import streamlit as st
import pandas as pd
import joblib
import re # ูุงุณุชุฎุฏุงู ุงูุชุนุงุจูุฑ ุงูููุทูุฉ (Regular Expressions)
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer # ูุฏ ูุง ุชุญุชุงุฌูุง ุฅุฐุง ูู ุชุณุชุฎุฏู Stemming

# ุชูุฒูู ุจูุงูุงุช NLTK ุงูุถุฑูุฑูุฉ (ูุฑุฉ ูุงุญุฏุฉ ููุท)
# ูุฌุจ ุงูุชุฃูุฏ ูู ุฃู ูุฐู ุงูุจูุงูุงุช ูุชุงุญุฉ ุนูู ุฎุงุฏู Streamlit
# ูู ุจุนุถ ุงูุฃุญูุงู ูุฏ ุชุญุชุงุฌ ุฅูู ุฅุถุงูุฉ ูุฐู ุงูุฃุณุทุฑ ูู ุจุฏุงูุฉ app.py ูุถูุงู ุงูุชูุฒูู
try:
    stopwords.words('english')
except LookupError:
    nltk.download('stopwords')
    st.info("ุชู ุชูุฒูู NLTK stopwords.")

# --- ุชุนุฑูู ุฏุงูุฉ ูุนุงูุฌุฉ ุงููุตูุต (Preprocessing Function) ---
# ูุฐู ุงูุฏุงูุฉ ูุฌุจ ุฃู ุชููู ูุทุงุจูุฉ ุชูุงูุงู ููุฏุงูุฉ ุงูุชู ุงุณุชุฎุฏูุชูุง ูู Notebook ูุชุฏุฑูุจ ุงูููุฏูู
def preprocess_text(text):
    # 1. ุชุญููู ุงููุต ุฅูู ุญุฑูู ุตุบูุฑุฉ
    text = text.lower()
    
    # 2. ุฅุฒุงูุฉ ุนูุงูุงุช ุงูุชุฑููู ูุงูุฃุฑูุงู (ุงูุงุญุชูุงุธ ููุท ุจุงูุฃุญุฑู ุงูุฃุจุฌุฏูุฉ ูุงููุณุงูุงุช)
    text = re.sub(r'[^a-z\s]', '', text)
    
    # 3. ุชูุณูู ุงููุต ุฅูู ูููุงุช
    tokens = text.split()
    
    # 4. ุฅุฒุงูุฉ ุงููููุงุช ุงููุชูููุฉ (Stopwords)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    
    # 5. Stemming (ุงุฎุชูุงุฑูุ ุฅุฐุง ููุช ูุฏ ุงุณุชุฎุฏูุชู ูู ุชุฏุฑูุจ ุงูููุฏูู)
    # stemmer = PorterStemmer()
    # tokens = [stemmer.stem(word) for word in tokens]
    
    # 6. ุฏูุฌ ุงููููุงุช ูุฑุฉ ุฃุฎุฑู ูู ูุต ูุงุญุฏ
    cleaned_text = ' '.join(tokens)
    
    return cleaned_text

# --- ุฅุนุฏุงุฏุงุช ุงูุตูุญุฉ ---
st.set_page_config(
    page_title="ุชุทุจูู ุชุญููู ุขุฑุงุก ุงูุนููุงุก (NLP)",
    page_icon="๐ฌ",
    layout="centered"
)

# --- ุชุญููู ุฃุฏุงุฉ ุชุญููู ุงููุตูุต (Vectorizer) ูููุฏูู ุชุญููู ุงููุดุงุนุฑ ---
try:
    # ุชุฃูุฏ ุฃู ูุฐู ุงูุฃุณูุงุก ูุงููุณุงุฑุงุช ูุทุงุจูุฉ ุชูุงูุงู ููููุงุชู ุงููุญููุธุฉ
    vectorizer = joblib.load('models/tfidf_vectorizer.joblib')
    sentiment_model = joblib.load('models/sentiment_classifier_model.joblib')
except FileNotFoundError:
    st.error("ูููุงุช ุงูููุฏูู ุฃู Vectorizer ุบูุฑ ููุฌูุฏุฉ! ูุฑุฌู ุงูุชุฃูุฏ ูู ูุฌูุฏ 'tfidf_vectorizer.joblib' ู 'sentiment_classifier_model.joblib' ูู ูุฌูุฏ 'models'.")
    st.stop()
except Exception as e:
    st.error(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุชุญููู ุงูููุฏููุงุช: {e}")
    st.stop()

# --- ุนููุงู ุงูุชุทุจูู ูุงููุตู ---
st.title('๐ฌ ุชุทุจูู ุชุญููู ุขุฑุงุก ุงูุนููุงุก (NLP)')
st.write("ุฃุฏุฎู ูุฑุงุฌุนุฉ ุงูุนููู ุฃู ุชุนูููู ููุง ูุชุญููู ูุดุงุนุฑู ูุงุณุชุฎูุงุต ุงูุฃููุงุฑ ุงูุฑุฆูุณูุฉ.")
st.write("---")

# --- ูุณู ุฅุฏุฎุงู ุงููุณุชุฎุฏู ---
user_review = st.text_area("ุฃุฏุฎู ูุฑุงุฌุนุฉ ุงูุนููู ููุง:", height=150)

# --- ุฒุฑ ุงูุชุญููู ูููุทู ุงูุชูุจุค ---
if st.button("ุชุญููู ุงููุฑุงุฌุนุฉ", type="primary"):
    if user_review:
        # 1. ูุนุงูุฌุฉ ุงููุต ุงููุฏุฎู
        cleaned_review = preprocess_text(user_review)
        
        # 2. ุชุญููู ุงููุต ุงููุนุงูุฌ ุฅูู ููุฒุงุช ุฑูููุฉ ุจุงุณุชุฎุฏุงู Vectorizer
        # ููุงุญุธุฉ: ูุฌุจ ุฃู ููุฑุฑ ูุงุฆูุฉ (list) ุญุชู ูู ูุงูุช ุชุญุชูู ุนูู ูุต ูุงุญุฏ
        vectorized_review = vectorizer.transform([cleaned_review])
        
        # 3. ุฅุฌุฑุงุก ุงูุชูุจุค ุจุงููุดุงุนุฑ ุจุงุณุชุฎุฏุงู ุงูููุฏูู
        prediction = sentiment_model.predict(vectorized_review)
        
        # 4. ุงูุญุตูู ุนูู ุงุญุชูุงููุฉ ูู ูุฆุฉ (ุงุฎุชูุงุฑูุ ูููู ูุนุทู ุฑุคูุฉ ุฃูุถู)
        prediction_proba = sentiment_model.predict_proba(vectorized_review)
        
        # 5. ุชูุณูุฑ ุงููุชูุฌุฉ ูุนุฑุถูุง
        sentiment_labels = ['ุณูุจูุฉ', 'ูุญุงูุฏุฉ', 'ุฅูุฌุงุจูุฉ'] # ูุฌุจ ุฃู ุชุชุทุงุจู ูุน ุชุฑุชูุจ ุงููุฆุงุช ูู ุจูุงูุงุชู
        predicted_sentiment = sentiment_labels[prediction[0]]
        
        st.write("---")
        st.subheader("ูุชุงุฆุฌ ุงูุชุญููู:")
        
        if predicted_sentiment == 'ุฅูุฌุงุจูุฉ':
            st.success(f"ุงููุดุงุนุฑ ุงููุชููุนุฉ: **{predicted_sentiment}** ๐")
        elif predicted_sentiment == 'ุณูุจูุฉ':
            st.error(f"ุงููุดุงุนุฑ ุงููุชููุนุฉ: **{predicted_sentiment}** ๐")
        else: # ูุญุงูุฏุฉ
            st.info(f"ุงููุดุงุนุฑ ุงููุชููุนุฉ: **{predicted_sentiment}** ๐")
        
        # ุนุฑุถ ุงูุงุญุชูุงููุงุช ููู ูุฆุฉ
        st.write(f"ุงุญุชูุงููุฉ ุงูุณูุจูุฉ: {prediction_proba[0][0]:.2%}")
        st.write(f"ุงุญุชูุงููุฉ ุงููุญุงูุฏุฉ: {prediction_proba[0][1]:.2%}")
        st.write(f"ุงุญุชูุงููุฉ ุงูุฅูุฌุงุจูุฉ: {prediction_proba[0][2]:.2%}")

        # ูููู ููุง ุฅุถุงูุฉ ุฌุฒุก ูุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุชุงุญูุฉ ุฅุฐุง ูุงู ูุฏูู ููุฏูู ูุฐูู
        # st.subheader("ุงููููุงุช ุงูููุชุงุญูุฉ/ุงูููุงุถูุน ุงูุฑุฆูุณูุฉ:")
        # st.write("... (ุณูุชู ุนุฑุถูุง ููุง)")

    else:
        st.warning("ุงูุฑุฌุงุก ุฅุฏุฎุงู ูุต ูุชุญูููู.", icon="โ๏ธ")